{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-10T22:50:11.585815Z","iopub.execute_input":"2021-06-10T22:50:11.587348Z","iopub.status.idle":"2021-06-10T22:50:11.598210Z","shell.execute_reply.started":"2021-06-10T22:50:11.587259Z","shell.execute_reply":"2021-06-10T22:50:11.597071Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"in the above cell: imports","metadata":{}},{"cell_type":"markdown","source":"# **1.Loading data**\nloading testing and training data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.599716Z","iopub.execute_input":"2021-06-10T22:50:11.600391Z","iopub.status.idle":"2021-06-10T22:50:11.648167Z","shell.execute_reply.started":"2021-06-10T22:50:11.600353Z","shell.execute_reply":"2021-06-10T22:50:11.647293Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.649295Z","iopub.execute_input":"2021-06-10T22:50:11.649489Z","iopub.status.idle":"2021-06-10T22:50:11.672726Z","shell.execute_reply.started":"2021-06-10T22:50:11.649467Z","shell.execute_reply":"2021-06-10T22:50:11.671805Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Pclass                                          Name     Sex  \\\n0          892       3                              Kelly, Mr. James    male   \n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n2          894       2                     Myles, Mr. Thomas Francis    male   \n3          895       3                              Wirz, Mr. Albert    male   \n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n0  34.5      0      0   330911   7.8292   NaN        Q  \n1  47.0      1      0   363272   7.0000   NaN        S  \n2  62.0      0      0   240276   9.6875   NaN        Q  \n3  27.0      0      0   315154   8.6625   NaN        S  \n4  22.0      1      1  3101298  12.2875   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"replacing the string values with numerical values to be easier in processing","metadata":{}},{"cell_type":"code","source":"replace_with_nums = { \"Embarked\": {\"S\": 0, \"C\": 1, \"Q\": 2 },\"Sex\": {\"male\": 0, \"female\": 1}}\ntrain_data.replace(replace_with_nums, inplace=True)\ntest_data.replace(replace_with_nums, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.674316Z","iopub.execute_input":"2021-06-10T22:50:11.674643Z","iopub.status.idle":"2021-06-10T22:50:11.686422Z","shell.execute_reply.started":"2021-06-10T22:50:11.674610Z","shell.execute_reply":"2021-06-10T22:50:11.685505Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# **2.Pre-processing**","metadata":{}},{"cell_type":"markdown","source":"# 2.1 Training data pre-processing","metadata":{}},{"cell_type":"markdown","source":"getting information about training data to know what is needed in the pre-processing phase","metadata":{}},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.687681Z","iopub.execute_input":"2021-06-10T22:50:11.687981Z","iopub.status.idle":"2021-06-10T22:50:11.713698Z","shell.execute_reply.started":"2021-06-10T22:50:11.687948Z","shell.execute_reply":"2021-06-10T22:50:11.713017Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    int64  \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    float64\ndtypes: float64(3), int64(6), object(3)\nmemory usage: 83.7+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.714487Z","iopub.execute_input":"2021-06-10T22:50:11.714768Z","iopub.status.idle":"2021-06-10T22:50:11.745964Z","shell.execute_reply.started":"2021-06-10T22:50:11.714741Z","shell.execute_reply":"2021-06-10T22:50:11.745505Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       PassengerId    Survived      Pclass         Sex         Age  \\\ncount   891.000000  891.000000  891.000000  891.000000  714.000000   \nmean    446.000000    0.383838    2.308642    0.352413   29.699118   \nstd     257.353842    0.486592    0.836071    0.477990   14.526497   \nmin       1.000000    0.000000    1.000000    0.000000    0.420000   \n25%     223.500000    0.000000    2.000000    0.000000   20.125000   \n50%     446.000000    0.000000    3.000000    0.000000   28.000000   \n75%     668.500000    1.000000    3.000000    1.000000   38.000000   \nmax     891.000000    1.000000    3.000000    1.000000   80.000000   \n\n            SibSp       Parch        Fare    Embarked  \ncount  891.000000  891.000000  891.000000  889.000000  \nmean     0.523008    0.381594   32.204208    0.362205  \nstd      1.102743    0.806057   49.693429    0.636157  \nmin      0.000000    0.000000    0.000000    0.000000  \n25%      0.000000    0.000000    7.910400    0.000000  \n50%      0.000000    0.000000   14.454200    0.000000  \n75%      1.000000    0.000000   31.000000    1.000000  \nmax      8.000000    6.000000  512.329200    2.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>889.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>0.352413</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n      <td>0.362205</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>0.477990</td>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n      <td>0.636157</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n      <td>2.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2.1.1 Checking for null values","metadata":{}},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.747357Z","iopub.execute_input":"2021-06-10T22:50:11.747643Z","iopub.status.idle":"2021-06-10T22:50:11.753025Z","shell.execute_reply.started":"2021-06-10T22:50:11.747615Z","shell.execute_reply":"2021-06-10T22:50:11.752516Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"get percentage of null values in each column to know how to handle them","metadata":{}},{"cell_type":"code","source":"print(\"% of Cabin null values: \", (train_data['Cabin'].isnull().sum()/891)*100)\nprint(\"% of Age null values: \",(train_data['Age'].isnull().sum()/891)*100)\nprint(\"% of Age null values: \",(train_data['Embarked'].isnull().sum()/891)*100)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.754058Z","iopub.execute_input":"2021-06-10T22:50:11.754414Z","iopub.status.idle":"2021-06-10T22:50:11.771338Z","shell.execute_reply.started":"2021-06-10T22:50:11.754387Z","shell.execute_reply":"2021-06-10T22:50:11.770323Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"% of Cabin null values:  77.10437710437711\n% of Age null values:  19.865319865319865\n% of Age null values:  0.22446689113355783\n","output_type":"stream"}]},{"cell_type":"markdown","source":"columns with null values more than 30% should be omitted, so i will drop cabin column","metadata":{}},{"cell_type":"markdown","source":"drop cabin column:","metadata":{}},{"cell_type":"code","source":"train_data = train_data.drop(['Cabin'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.772338Z","iopub.execute_input":"2021-06-10T22:50:11.772550Z","iopub.status.idle":"2021-06-10T22:50:11.784157Z","shell.execute_reply.started":"2021-06-10T22:50:11.772529Z","shell.execute_reply":"2021-06-10T22:50:11.783380Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Age has less nan values than 30%, so i chose to replace nan values with column mean","metadata":{}},{"cell_type":"code","source":"train_data['Age'].fillna((train_data['Age'].mean()), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.785412Z","iopub.execute_input":"2021-06-10T22:50:11.785601Z","iopub.status.idle":"2021-06-10T22:50:11.798371Z","shell.execute_reply.started":"2021-06-10T22:50:11.785583Z","shell.execute_reply":"2021-06-10T22:50:11.797588Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Embarked has only 2 nan values so i will drop their rows as dropping them won't affect the results","metadata":{}},{"cell_type":"code","source":"train_data.dropna(subset=['Embarked'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.799403Z","iopub.execute_input":"2021-06-10T22:50:11.799666Z","iopub.status.idle":"2021-06-10T22:50:11.828128Z","shell.execute_reply.started":"2021-06-10T22:50:11.799583Z","shell.execute_reply":"2021-06-10T22:50:11.827069Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"recheck that all our data are filled","metadata":{}},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.830827Z","iopub.execute_input":"2021-06-10T22:50:11.831067Z","iopub.status.idle":"2021-06-10T22:50:11.839576Z","shell.execute_reply.started":"2021-06-10T22:50:11.831045Z","shell.execute_reply":"2021-06-10T22:50:11.838971Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"PassengerId    0\nSurvived       0\nPclass         0\nName           0\nSex            0\nAge            0\nSibSp          0\nParch          0\nTicket         0\nFare           0\nEmbarked       0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2.1.2 drop unique features","metadata":{}},{"cell_type":"code","source":"train_data = train_data.drop(['PassengerId'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.840529Z","iopub.execute_input":"2021-06-10T22:50:11.840921Z","iopub.status.idle":"2021-06-10T22:50:11.849479Z","shell.execute_reply.started":"2021-06-10T22:50:11.840893Z","shell.execute_reply":"2021-06-10T22:50:11.848719Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"checking for duplicates in data after dropping the id column that made each row unique","metadata":{}},{"cell_type":"markdown","source":"# 2.1.3 split training data to training data and validation data","metadata":{}},{"cell_type":"markdown","source":"using shuffle=True prevents data from overfitting","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntraining_data, validation_data = train_test_split(\n    train_data, test_size=0.3,  random_state=40,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:11.850457Z","iopub.execute_input":"2021-06-10T22:50:11.850804Z","iopub.status.idle":"2021-06-10T22:50:12.705144Z","shell.execute_reply.started":"2021-06-10T22:50:11.850776Z","shell.execute_reply":"2021-06-10T22:50:12.704398Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# 2.2 Testing data pre-processing","metadata":{}},{"cell_type":"markdown","source":"get info about testing data","metadata":{}},{"cell_type":"code","source":"test_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:12.706174Z","iopub.execute_input":"2021-06-10T22:50:12.706471Z","iopub.status.idle":"2021-06-10T22:50:12.719115Z","shell.execute_reply.started":"2021-06-10T22:50:12.706443Z","shell.execute_reply":"2021-06-10T22:50:12.718049Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    int64  \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    int64  \ndtypes: float64(2), int64(6), object(3)\nmemory usage: 36.0+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:12.720487Z","iopub.execute_input":"2021-06-10T22:50:12.720775Z","iopub.status.idle":"2021-06-10T22:50:12.759289Z","shell.execute_reply.started":"2021-06-10T22:50:12.720743Z","shell.execute_reply":"2021-06-10T22:50:12.758327Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"       PassengerId      Pclass         Sex         Age       SibSp  \\\ncount   418.000000  418.000000  418.000000  332.000000  418.000000   \nmean   1100.500000    2.265550    0.363636   30.272590    0.447368   \nstd     120.810458    0.841838    0.481622   14.181209    0.896760   \nmin     892.000000    1.000000    0.000000    0.170000    0.000000   \n25%     996.250000    1.000000    0.000000   21.000000    0.000000   \n50%    1100.500000    3.000000    0.000000   27.000000    0.000000   \n75%    1204.750000    3.000000    1.000000   39.000000    1.000000   \nmax    1309.000000    3.000000    1.000000   76.000000    8.000000   \n\n            Parch        Fare    Embarked  \ncount  418.000000  417.000000  418.000000  \nmean     0.392344   35.627188    0.464115  \nstd      0.981429   55.907576    0.685516  \nmin      0.000000    0.000000    0.000000  \n25%      0.000000    7.895800    0.000000  \n50%      0.000000   14.454200    0.000000  \n75%      0.000000   31.500000    1.000000  \nmax      9.000000  512.329200    2.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>418.000000</td>\n      <td>418.000000</td>\n      <td>418.000000</td>\n      <td>332.000000</td>\n      <td>418.000000</td>\n      <td>418.000000</td>\n      <td>417.000000</td>\n      <td>418.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1100.500000</td>\n      <td>2.265550</td>\n      <td>0.363636</td>\n      <td>30.272590</td>\n      <td>0.447368</td>\n      <td>0.392344</td>\n      <td>35.627188</td>\n      <td>0.464115</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>120.810458</td>\n      <td>0.841838</td>\n      <td>0.481622</td>\n      <td>14.181209</td>\n      <td>0.896760</td>\n      <td>0.981429</td>\n      <td>55.907576</td>\n      <td>0.685516</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>892.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.170000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>996.250000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.895800</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1100.500000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>27.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1204.750000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>39.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.500000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1309.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>76.000000</td>\n      <td>8.000000</td>\n      <td>9.000000</td>\n      <td>512.329200</td>\n      <td>2.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"check for null values in the testing","metadata":{}},{"cell_type":"code","source":"test_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:12.760117Z","iopub.execute_input":"2021-06-10T22:50:12.760336Z","iopub.status.idle":"2021-06-10T22:50:12.767342Z","shell.execute_reply.started":"2021-06-10T22:50:12.760314Z","shell.execute_reply":"2021-06-10T22:50:12.766539Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"PassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"as training data, drop cabin column and fill age with mean value","metadata":{}},{"cell_type":"code","source":"test_data = test_data.drop(['Cabin'], axis=1)\ntest_data['Age'].fillna((test_data['Age'].mean()), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:12.768539Z","iopub.execute_input":"2021-06-10T22:50:12.768927Z","iopub.status.idle":"2021-06-10T22:50:12.780497Z","shell.execute_reply.started":"2021-06-10T22:50:12.768894Z","shell.execute_reply":"2021-06-10T22:50:12.779325Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"fill fare column using interpolate which fill it with the average of the value before and the value after it, but it can't be used if there's more than two consecutive nan ","metadata":{}},{"cell_type":"code","source":"test_data['Fare'].interpolate(method='linear', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:12.782672Z","iopub.execute_input":"2021-06-10T22:50:12.782888Z","iopub.status.idle":"2021-06-10T22:50:12.792552Z","shell.execute_reply.started":"2021-06-10T22:50:12.782858Z","shell.execute_reply":"2021-06-10T22:50:12.791695Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# **3.Training**","metadata":{}},{"cell_type":"markdown","source":"importing the model that will be used","metadata":{}},{"cell_type":"markdown","source":"# 3.1 choosing the model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:12.793975Z","iopub.execute_input":"2021-06-10T22:50:12.794378Z","iopub.status.idle":"2021-06-10T22:50:13.020911Z","shell.execute_reply.started":"2021-06-10T22:50:12.794352Z","shell.execute_reply":"2021-06-10T22:50:13.020059Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# 3.2 Loading data","metadata":{}},{"cell_type":"markdown","source":"specify the parameters used","metadata":{}},{"cell_type":"code","source":"y = training_data[\"Survived\"] # selecting y in training phase which is similar to the output feature we want to predict\ny_testing= validation_data[\"Survived\"] #the output feature we want to predict\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\"] #important features that will be considered\n#getting the data: \nX = pd.get_dummies(training_data[features]) \nX_testing= pd.get_dummies(validation_data[features])\nX_test = pd.get_dummies(test_data[features])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:13.021687Z","iopub.execute_input":"2021-06-10T22:50:13.021897Z","iopub.status.idle":"2021-06-10T22:50:13.038531Z","shell.execute_reply.started":"2021-06-10T22:50:13.021876Z","shell.execute_reply":"2021-06-10T22:50:13.037640Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# 3.3 Parameters tuning","metadata":{}},{"cell_type":"markdown","source":"this step is done similar to the previous assignment\n2 for loops are used to get the best combination between these two parameters: n_estimators which is the number of trees that will be used and max_depth is how deep the tree will go","metadata":{}},{"cell_type":"code","source":"candidate_max_depth = [2,3,4,5,7]\ncandidate_n_estimators = [40,50,70,100,120,150]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor max_depth in candidate_max_depth:\n    for n_estimators in candidate_n_estimators:\n        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=1)\n        model.fit(X,y)\n        print(\"at depth %d, and n_estimators %d\" %(max_depth, n_estimators))\n        print(model.score(X_testing, y_testing))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:13.039578Z","iopub.execute_input":"2021-06-10T22:50:13.039832Z","iopub.status.idle":"2021-06-10T22:50:18.549873Z","shell.execute_reply.started":"2021-06-10T22:50:13.039805Z","shell.execute_reply":"2021-06-10T22:50:18.548998Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"at depth 2, and n_estimators 40\n0.8052434456928839\nat depth 2, and n_estimators 50\n0.8052434456928839\nat depth 2, and n_estimators 70\n0.8089887640449438\nat depth 2, and n_estimators 100\n0.8052434456928839\nat depth 2, and n_estimators 120\n0.8052434456928839\nat depth 2, and n_estimators 150\n0.8052434456928839\nat depth 3, and n_estimators 40\n0.8202247191011236\nat depth 3, and n_estimators 50\n0.8164794007490637\nat depth 3, and n_estimators 70\n0.8164794007490637\nat depth 3, and n_estimators 100\n0.8164794007490637\nat depth 3, and n_estimators 120\n0.8127340823970037\nat depth 3, and n_estimators 150\n0.8202247191011236\nat depth 4, and n_estimators 40\n0.8164794007490637\nat depth 4, and n_estimators 50\n0.8164794007490637\nat depth 4, and n_estimators 70\n0.8127340823970037\nat depth 4, and n_estimators 100\n0.8164794007490637\nat depth 4, and n_estimators 120\n0.8164794007490637\nat depth 4, and n_estimators 150\n0.8164794007490637\nat depth 5, and n_estimators 40\n0.8127340823970037\nat depth 5, and n_estimators 50\n0.8127340823970037\nat depth 5, and n_estimators 70\n0.8127340823970037\nat depth 5, and n_estimators 100\n0.8127340823970037\nat depth 5, and n_estimators 120\n0.8127340823970037\nat depth 5, and n_estimators 150\n0.8089887640449438\nat depth 7, and n_estimators 40\n0.8164794007490637\nat depth 7, and n_estimators 50\n0.8202247191011236\nat depth 7, and n_estimators 70\n0.8089887640449438\nat depth 7, and n_estimators 100\n0.8052434456928839\nat depth 7, and n_estimators 120\n0.8052434456928839\nat depth 7, and n_estimators 150\n0.8089887640449438\n","output_type":"stream"}]},{"cell_type":"markdown","source":"there are three combinations that are equal but for me the best choice is 150, 3","metadata":{}},{"cell_type":"markdown","source":"fitting the model and printing the final score, using random state = 1 to prevent overfitting ","metadata":{}},{"cell_type":"code","source":" model = RandomForestClassifier(n_estimators=150, max_depth=3, random_state=1)\n model.fit(X,y)\n print(model.score(X_testing, y_testing))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:18.550741Z","iopub.execute_input":"2021-06-10T22:50:18.550932Z","iopub.status.idle":"2021-06-10T22:50:18.757888Z","shell.execute_reply.started":"2021-06-10T22:50:18.550910Z","shell.execute_reply":"2021-06-10T22:50:18.757110Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"0.8202247191011236\n","output_type":"stream"}]},{"cell_type":"markdown","source":"predicting and saving data","metadata":{}},{"cell_type":"code","source":"\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2021-06-10T22:50:18.758707Z","iopub.execute_input":"2021-06-10T22:50:18.758901Z","iopub.status.idle":"2021-06-10T22:50:18.787588Z","shell.execute_reply.started":"2021-06-10T22:50:18.758880Z","shell.execute_reply":"2021-06-10T22:50:18.787077Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Your submission was successfully saved!\n","output_type":"stream"}]}]}